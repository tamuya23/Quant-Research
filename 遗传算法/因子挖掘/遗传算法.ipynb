{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6820edd-daa3-4d5d-9977-d1d84689d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/wangs/rs/lib')\n",
    "import ff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62fb1478-85b5-4020-950d-0b4a6365d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr,spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efee36b5-2924-432e-bef1-961be56f3c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gplearn.genetic import SymbolicRegressor,SymbolicTransformer\n",
    "from gplearn import fitness\n",
    "from gplearn.functions import make_function\n",
    "from gplearn.fitness import make_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "051ece45-749c-4fef-8159-851cdcd71429",
   "metadata": {},
   "outputs": [],
   "source": [
    "post=ff.read('post')\n",
    "filter0=ff.filter0\n",
    "close=ff.read('close')*post*filter0\n",
    "open_=ff.read('open')*post*filter0\n",
    "high=ff.read('high')*post*filter0\n",
    "low=ff.read('low')*post*filter0\n",
    "vol=ff.read('vol')*filter0\n",
    "amount=ff.read('amount')*post*filter0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2a70b25-f8ba-41a9-926c-e9414f375ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20100104</th>\n",
       "      <th>20100105</th>\n",
       "      <th>20100106</th>\n",
       "      <th>20100107</th>\n",
       "      <th>20100108</th>\n",
       "      <th>20100111</th>\n",
       "      <th>20100112</th>\n",
       "      <th>20100113</th>\n",
       "      <th>20100114</th>\n",
       "      <th>20100115</th>\n",
       "      <th>...</th>\n",
       "      <th>20240517</th>\n",
       "      <th>20240520</th>\n",
       "      <th>20240521</th>\n",
       "      <th>20240522</th>\n",
       "      <th>20240523</th>\n",
       "      <th>20240524</th>\n",
       "      <th>20240527</th>\n",
       "      <th>20240528</th>\n",
       "      <th>20240529</th>\n",
       "      <th>20240530</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000001.SZ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1332.86246</td>\n",
       "      <td>1328.19394</td>\n",
       "      <td>1348.03515</td>\n",
       "      <td>1349.20228</td>\n",
       "      <td>1330.52820</td>\n",
       "      <td>1320.02403</td>\n",
       "      <td>1343.36663</td>\n",
       "      <td>1330.52820</td>\n",
       "      <td>1314.18838</td>\n",
       "      <td>1297.84856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000002.SZ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1635.33600</td>\n",
       "      <td>1668.04272</td>\n",
       "      <td>1669.85976</td>\n",
       "      <td>1708.01760</td>\n",
       "      <td>1737.09024</td>\n",
       "      <td>1633.51896</td>\n",
       "      <td>1611.71448</td>\n",
       "      <td>1548.11808</td>\n",
       "      <td>1559.02032</td>\n",
       "      <td>1502.69208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000004.SZ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>46.24832</td>\n",
       "      <td>48.52416</td>\n",
       "      <td>47.34560</td>\n",
       "      <td>47.14240</td>\n",
       "      <td>46.28896</td>\n",
       "      <td>44.74464</td>\n",
       "      <td>44.37888</td>\n",
       "      <td>43.40352</td>\n",
       "      <td>43.40352</td>\n",
       "      <td>42.63136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000005.SZ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000006.SZ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>171.67680</td>\n",
       "      <td>166.11320</td>\n",
       "      <td>166.51060</td>\n",
       "      <td>168.89500</td>\n",
       "      <td>164.52360</td>\n",
       "      <td>160.15220</td>\n",
       "      <td>158.16520</td>\n",
       "      <td>153.79380</td>\n",
       "      <td>155.78080</td>\n",
       "      <td>150.21720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873726.BJ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873806.BJ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873833.BJ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920002.BJ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T00018.SH</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5543 rows × 3498 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           20100104  20100105  20100106  20100107  20100108  20100111  \\\n",
       "000001.SZ       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "000002.SZ       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "000004.SZ       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "000005.SZ       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "000006.SZ       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "873726.BJ       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "873806.BJ       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "873833.BJ       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "920002.BJ       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "T00018.SH       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "           20100112  20100113  20100114  20100115  ...    20240517  \\\n",
       "000001.SZ       NaN       NaN       NaN       NaN  ...  1332.86246   \n",
       "000002.SZ       NaN       NaN       NaN       NaN  ...  1635.33600   \n",
       "000004.SZ       NaN       NaN       NaN       NaN  ...    46.24832   \n",
       "000005.SZ       NaN       NaN       NaN       NaN  ...         NaN   \n",
       "000006.SZ       NaN       NaN       NaN       NaN  ...   171.67680   \n",
       "...             ...       ...       ...       ...  ...         ...   \n",
       "873726.BJ       NaN       NaN       NaN       NaN  ...         NaN   \n",
       "873806.BJ       NaN       NaN       NaN       NaN  ...         NaN   \n",
       "873833.BJ       NaN       NaN       NaN       NaN  ...         NaN   \n",
       "920002.BJ       NaN       NaN       NaN       NaN  ...         NaN   \n",
       "T00018.SH       NaN       NaN       NaN       NaN  ...         NaN   \n",
       "\n",
       "             20240520    20240521    20240522    20240523    20240524  \\\n",
       "000001.SZ  1328.19394  1348.03515  1349.20228  1330.52820  1320.02403   \n",
       "000002.SZ  1668.04272  1669.85976  1708.01760  1737.09024  1633.51896   \n",
       "000004.SZ    48.52416    47.34560    47.14240    46.28896    44.74464   \n",
       "000005.SZ         NaN         NaN         NaN         NaN         NaN   \n",
       "000006.SZ   166.11320   166.51060   168.89500   164.52360   160.15220   \n",
       "...               ...         ...         ...         ...         ...   \n",
       "873726.BJ         NaN         NaN         NaN         NaN         NaN   \n",
       "873806.BJ         NaN         NaN         NaN         NaN         NaN   \n",
       "873833.BJ         NaN         NaN         NaN         NaN         NaN   \n",
       "920002.BJ         NaN         NaN         NaN         NaN         NaN   \n",
       "T00018.SH         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "             20240527    20240528    20240529    20240530  \n",
       "000001.SZ  1343.36663  1330.52820  1314.18838  1297.84856  \n",
       "000002.SZ  1611.71448  1548.11808  1559.02032  1502.69208  \n",
       "000004.SZ    44.37888    43.40352    43.40352    42.63136  \n",
       "000005.SZ         NaN         NaN         NaN         NaN  \n",
       "000006.SZ   158.16520   153.79380   155.78080   150.21720  \n",
       "...               ...         ...         ...         ...  \n",
       "873726.BJ         NaN         NaN         NaN         NaN  \n",
       "873806.BJ         NaN         NaN         NaN         NaN  \n",
       "873833.BJ         NaN         NaN         NaN         NaN  \n",
       "920002.BJ         NaN         NaN         NaN         NaN  \n",
       "T00018.SH         NaN         NaN         NaN         NaN  \n",
       "\n",
       "[5543 rows x 3498 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a49b69e2-547d-41eb-97b2-a1aa5b21ec5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcal_returns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mcal_returns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcumsum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'年化收益率'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'年化波动率'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'夏普率'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'年化收益率'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'年化波动率'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'最大回撤'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcal_downdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'收益回撤比'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'年化收益率'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'最大回撤'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'胜率'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'盈亏比'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/rs/lib/ff.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ff.cal_returns??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77af96e5-484f-4f54-b5f7-14280634fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkv=(ff.read('mkv','factor')*filter0).loc[close.index,'20200101':'20210101']\n",
    "mkv_s=mkv.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f75b3081-dc34-4b6f-b7f5-a57c29618906",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = pd.read_pickle('/mydata2/wangs/data/dict_ind_matrix_sw1.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "815ef9c2-d652-4d5b-bf93-2bd95c1ab4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt20=close.shift(-20,axis=1)/close - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416bde7b-de44-4145-91e4-61b1c1613670",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_test=pd.DataFrame({\n",
    "                'accelerated_turnover_rank_RC':pd.DataFrame(ff.read('accelerated_turnover_rank_RC').loc[ff.read('synergy').index,'20200101':'20210101'],index=open_.index).values.reshape(-1),\n",
    "                         'CSK_XYY_UP_DOWN_120D_RC':pd.DataFrame(ff.read('CSK_XYY_UP_DOWN_120D_RC').loc[ff.read('synergy').index,'20200101':'20210101'],index=open_.index).values.reshape(-1),\n",
    "                         'high_fre_vol_RC':pd.DataFrame(ff.read('high_fre_vol_RC').loc[ff.read('synergy').index,'20200101':'20210101'],index=open_.index).values.reshape(-1),\n",
    "                         'high_fre_diff_vol_RC':pd.DataFrame(ff.read('high_fre_diff_vol_RC').loc[ff.read('synergy').index,'20200101':'20210101'],index=open_.index).values.reshape(-1),\n",
    "                         'high_fre_absdiff_vol_RC':pd.DataFrame(ff.read('high_fre_absdiff_vol_RC').loc[ff.read('synergy').index,'20200101':'20210101'],index=open_.index).values.reshape(-1),\n",
    "                         'peak_count_vol_RC':pd.DataFrame(ff.read('peak_count_vol_RC').loc[ff.read('synergy').index,'20200101':'20210101'],index=open_.index).values.reshape(-1),\n",
    "                         'overnightsmart20_RC':pd.DataFrame(ff.read('overnightsmart20_RC').loc[ff.read('synergy').index,'20200101':'20210101'],index=open_.index).values.reshape(-1),\n",
    "                         'CTR_RC':pd.DataFrame(ff.read('CTR_RC').loc[ff.read('synergy').index,'20200101':'20210101'],index=open_.index).values.reshape(-1),\n",
    "                         'jumpCTR_RC':pd.DataFrame(ff.read('jumpCTR_RC').loc[ff.read('synergy').index,'20200101':'20210101'],index=open_.index).values.reshape(-1),\n",
    "                         'turnover_rate_proportion_l':pd.DataFrame(ff.read('turnover_rate_proportion_l').loc[ff.read('synergy').index,'20200101':'20210101'],index=open_.index).values.reshape(-1),\n",
    "                         'synergy':pd.DataFrame(ff.read('synergy').loc[ff.read('synergy').index,'20200101':'20210101'],index=open_.index).values.reshape(-1),\n",
    "                        })\n",
    "test_code=[code for code in close.index for i in close.loc[:,'20200101':'20210101'].columns]\n",
    "test_date=close.loc[:,'20200101':'20210101'].columns.to_list() *len(close.index)\n",
    "stock_test['code']=test_code\n",
    "stock_test['date']=test_date\n",
    "stock_test['1'],stock_test['5'],stock_test['10'],stock_test['20'],stock_test['40'],stock_test['60']=1,5,10,20,40,60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf38623-d39a-4115-83c2-c37eb7ae9e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mkt=mkt20.loc[:,'20200101':'20210101'].values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05073005-d053-46e3-a42d-49983d3de2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c755333-c2f5-48a6-ad5a-e76553d7a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_code=close.index.to_list()  # list\n",
    "unique_date=close.loc[:,'20200101':'20210101'].columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21928f4-5b58-4c35-9ccb-d7a769bc7cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields=['accelerated_turnover_rank_RC','CSK_XYY_UP_DOWN_120D_RC','high_fre_vol_RC','high_fre_diff_vol_RC','high_fre_absdiff_vol_RC','peak_count_vol_RC','overnightsmart20_RC','CTR_RC','jumpCTR_RC','turnover_rate_proportion_l','synergy','1','5','20','40','60']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af54bf65-557d-4ba6-928a-1a7601714cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自带算子\n",
    "init_function = ['add','sub','mul','div','sqrt','log','inv','abs','neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d508209b-18fc-46a8-8cce-916c8fd782d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义算子\n",
    "def _Add(data1,data2):\n",
    "    if len(np.unique(data1))<=1 or len(np.unique(data2))<=1:\n",
    "        return np.zeros(len(data1))\n",
    "    else:\n",
    "        return np.add(data1,data2)\n",
    "    \n",
    "def _Sub(data1,data2):\n",
    "    if len(np.unique(data1))<=1 or len(np.unique(data2))<=1:\n",
    "        return np.zeros(len(data1))\n",
    "    else:\n",
    "        return np.subtract(data1,data2)\n",
    "    \n",
    "def _Mul(data1,data2):\n",
    "    if len(np.unique(data1))<=1 or len(np.unique(data2))<=1:\n",
    "        return np.zeros(len(data1))\n",
    "    else:\n",
    "        return np.multiply(data1,data2)\n",
    "    \n",
    "def _Div(data1,data2):\n",
    "    def protect_division(data1,data2):\n",
    "        with np.errstate(divide='ignore',invalid='ignore'):\n",
    "            return np.where(np.abs(data2)>0.001,np.divide(data1,data2),0.)\n",
    "    if len(np.unique(data1))<=1 or len(np.unique(data2))<=1:\n",
    "        return np.zeros(len(data1))\n",
    "    else:\n",
    "        return protect_division(data1,data2)\n",
    "    \n",
    "def _Sqrt(data):\n",
    "    if len(np.unique(data))<=1:\n",
    "        return np.zeros(len(data))\n",
    "    else:\n",
    "        return np.sqrt(np.abs(data))\n",
    "    \n",
    "def _Log(data):\n",
    "    def protect_log(data):\n",
    "        with np.errstate(divide='ignore',invalid='ignore'):\n",
    "            return np.where(np.abs(data) > 0.001, np.log(np.abs(data)), 0.)\n",
    "    if len(np.unique(data))<=1:\n",
    "        return np.zeros(len(data))\n",
    "    else:\n",
    "        return protect_log(data)\n",
    "    \n",
    "def _Inv(data):\n",
    "    data=np.array(data)\n",
    "    def protect_inv(data):\n",
    "        with np.errstate(divide='ignore',invalid='ignore'):\n",
    "            return np.where(np.abs(data) > 0.001, 1./data, 0.)\n",
    "    if len(np.unique(data))<=1:\n",
    "        return np.zeros(len(data))\n",
    "    else:\n",
    "        return protect_inv(data)\n",
    "\n",
    "def _ts_max(data,window): #历史rolling最大\n",
    "    window=window[0]\n",
    "    if window not in [5,10,20,40,60] or len(np.unique(data))<=2:\n",
    "        return np.zeros(len(data))\n",
    "    try:\n",
    "        df=pd.DataFrame({'data':data})\n",
    "        df['date']=test_date\n",
    "        df['code']=test_code\n",
    "        value=df.groupby('code')['data'].transform(lambda x:x.rolling(window).max())\n",
    "        return np.nan_to_num(value.values)\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "def _ts_min(data,window): #历史rolling最小\n",
    "    window=window[0]\n",
    "    if window not in [5,10,20,40,60] or len(np.unique(data))<=2:\n",
    "        return np.zeros(len(data))\n",
    "    try:\n",
    "        df=pd.DataFrame({'data':data})\n",
    "        df['date']=test_date\n",
    "        df['code']=test_code\n",
    "        value=df.groupby('code')['data'].transform(lambda x:x.rolling(window).min())\n",
    "        return np.nan_to_num(value.values)\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "def _ts_mid(data,window): #历史rolling中位数\n",
    "    window=window[0]\n",
    "    if window not in [5,10,20,40,60] or len(np.unique(data))<=2:\n",
    "        return np.zeros(len(data))\n",
    "    try:\n",
    "        df=pd.DataFrame({'data':data})\n",
    "        df['date']=test_date\n",
    "        df['code']=test_code\n",
    "        value=df.groupby('code')['data'].transform(lambda x:x.rolling(window).median())\n",
    "        return np.nan_to_num(value.values)\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "\n",
    "def _ts_mean(data,window):  #历史rolling平均\n",
    "    window=window[0]\n",
    "    if window not in [5,10,20,40,60] or len(np.unique(data))<=2:\n",
    "        return np.zeros(len(data))\n",
    "    try:\n",
    "        df=pd.DataFrame({'data':data})\n",
    "        df['date']=test_date\n",
    "        df['code']=test_code\n",
    "        value=df.groupby('code')['data'].transform(lambda x:x.rolling(window).mean())\n",
    "        return np.nan_to_num(value.values)\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "\n",
    "def _ts_std(data,window): #历史rolling std\n",
    "    window=window[0]\n",
    "    if window not in [5,10,20,40,60] or len(np.unique(data))<=2:\n",
    "        return np.zeros(len(data))\n",
    "    try:\n",
    "        df=pd.DataFrame({'data':data})\n",
    "        df['date']=test_date\n",
    "        df['code']=test_code\n",
    "        value=df.groupby('code')['data'].transform(lambda x:x.rolling(window).std())\n",
    "        return np.nan_to_num(value.values)\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "    \n",
    "    \n",
    "def _ts_sum(data,window): #历史rolling求和\n",
    "    window=window[0]\n",
    "    if window not in [5,10,20,40,60] or len(np.unique(data))<=2:\n",
    "        return np.zeros(len(data))\n",
    "    try:\n",
    "        df=pd.DataFrame({'data':data})\n",
    "        df['date']=test_date\n",
    "        df['code']=test_code\n",
    "        value=df.groupby('code')['data'].transform(lambda x:x.rolling(window).mean())\n",
    "        return np.nan_to_num(value.values*window)\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "    \n",
    "    \n",
    "def _ts_product(data,window): #历史rolling求积\n",
    "    window=window[0]\n",
    "    if window not in [5,10,20,40,60] or len(np.unique(data))<=2:\n",
    "        return np.zeros(len(data))\n",
    "    try:\n",
    "        df=pd.DataFrame({'data':np.log(data)})\n",
    "        df['date']=test_date\n",
    "        df['code']=test_code\n",
    "        value=df.groupby('code')['data'].transform(lambda x:x.rolling(window).mean())\n",
    "        return np.nan_to_num(np.exp(value.values*window))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "    \n",
    "def _delay(data,window):  # 几天以前的因子值\n",
    "    window=window[0]\n",
    "    if window not in [1,5,10,20,40,60] or len(np.unique(data))<=2:\n",
    "        return np.zeros(len(data))\n",
    "    try:\n",
    "        df=pd.DataFrame({'data':data})\n",
    "        df['date']=test_date\n",
    "        df['code']=test_code\n",
    "        value=df.groupby('code')['data'].transform(lambda x : x.shift(window))\n",
    "        return np.nan_to_num(value.values)\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "    \n",
    "def _delta(data,window):  # 因子值与几天前的因子值之差\n",
    "    window=window[0]\n",
    "    if window not in [1,5,10,20,40,60] or len(np.unique(data))<=2:\n",
    "        return np.zeros(len(data))\n",
    "    try:\n",
    "        df=pd.DataFrame({'data':data})\n",
    "        df['date']=test_date\n",
    "        df['code']=test_code\n",
    "        value=df.groupby('code')['data'].transform(lambda x : x.shift(window))\n",
    "        return np.nan_to_num(value.values)\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "    \n",
    "def _rank(data):  # 因子在截面上的分位数\n",
    "    if len(np.unique(data))<=2:\n",
    "        return np.zeros(len(data))\n",
    "    try:\n",
    "        df=pd.DataFrame({'data':data})\n",
    "        df['date']=test_date\n",
    "        df['code']=test_code\n",
    "        value=df.groupby('date')['data'].transform(lambda s : s.rank()/s.count())\n",
    "        return np.nan_to_num(value.values)\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "    \n",
    "    \n",
    "def _ts_rank(data,window):  # 因子在过去几天中的分位数\n",
    "    window=window[0]\n",
    "    if window not in [5,10,20,40,60] or len(np.unique(data))<=2:\n",
    "        return np.zeros(len(data))\n",
    "    try:\n",
    "        df=pd.DataFrame({'data':data})\n",
    "        df['date']=test_date\n",
    "        df['code']=test_code  \n",
    "        value=df.groupby('code')['data'].transform(lambda x:x.rolling(window).rank()/window)\n",
    "        return np.nan_to_num(value.values)\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "    \n",
    "    \n",
    "def _sigmoid(data):\n",
    "    data=np.array(data)\n",
    "    with np.errstate(over='ignore',under='ignore'):\n",
    "        return 1/(1+np.exp(-1*data))\n",
    "    \n",
    "    \n",
    "def _correlation(data1,data2,window):\n",
    "    window=window[0]\n",
    "    if window not in [5,10,20,40,60] or len(np.unique(data1))<=2 or len(np.unique(data2))<=2:\n",
    "        return np.zeros(len(data1))\n",
    "    try:\n",
    "        df=pd.DataFrame({'data1':data1,'data2':data2})\n",
    "        df['date']=test_date\n",
    "        df['code']=test_code\n",
    "        value=df.groupby('code').apply(lambda df : df.data1.rolling(window).corr(df.data2)) # 因为code排序是按顺序的所以可以用apply\n",
    "        return np.nan_to_num(value.values)\n",
    "    except:\n",
    "        return np.zeros(len(data1))\n",
    "    \n",
    "    \n",
    "def _covariance(data1,data2,window):\n",
    "    window=window[0]\n",
    "    if window not in [5,10,20,40,60] or len(np.unique(data1))<=2 or len(np.unique(data2))<=2:\n",
    "        return np.zeros(len(data1))\n",
    "    try:\n",
    "        df=pd.DataFrame({'data1':data1,'data2':data2})\n",
    "        df['date']=test_date\n",
    "        df['code']=test_code\n",
    "        value=df.groupby('code').apply(lambda df : df.data1.rolling(window).cov(df.data2)) # 因为code排序是按顺序的所以可以用apply\n",
    "        return np.nan_to_num(value.values)\n",
    "    except:\n",
    "        return np.zeros(len(data1))\n",
    "    \n",
    "    \n",
    "def _scale(data):\n",
    "    if len(np.unique(data))<=2:\n",
    "        return np.zeros(len(data))\n",
    "    else:\n",
    "        return np.divide(data,np.sum(np.abs(data)))\n",
    "    \n",
    "    \n",
    "def _decay_linear(data,window):  # 因子过去几天的加权平均值，权数随时间往前线性递减\n",
    "    window=window[0]    \n",
    "    if  window not in [5,10,20,40,60] or len(np.unique(data))<=2:\n",
    "        return np.zeros(len(data))\n",
    "    try:\n",
    "        w=np.arange(1,window+1)\n",
    "        w=w/np.sum(w)\n",
    "        df=pd.DataFrame({'data':data})\n",
    "        df['date']=test_date\n",
    "        df['code']=test_code\n",
    "        value=df.groupby('code').data.transform(lambda x:x.rolling(window).apply(lambda s:np.dot(w,s.values)).values)\n",
    "        return np.nan_to_num(value)\n",
    "    except:\n",
    "        return np.zeros(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362fb20f-9319-4ccd-b208-d6d2d097cb89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Add=make_function(function=_Add,name='Add',arity=2)\n",
    "Sub=make_function(function=_Sub,name='Sub',arity=2)\n",
    "Mul=make_function(function=_Mul,name='Mul',arity=2)\n",
    "Div=make_function(function=_Div,name='Div',arity=2)\n",
    "Log=make_function(function=_Log,name='Log',arity=1)\n",
    "Sqrt=make_function(function=_Sqrt,name='Sqrt',arity=1)\n",
    "Inv=make_function(function=_Inv,name='Inv',arity=1)\n",
    "ts_max=make_function(function=_ts_max,name='ts_max',arity=2) \n",
    "ts_min=make_function(function=_ts_min,name='ts_min',arity=2) \n",
    "ts_mid=make_function(function=_ts_mid,name='ts_mid',arity=2) \n",
    "ts_mean=make_function(function=_ts_mean,name='ts_mean',arity=2) \n",
    "ts_std=make_function(function=_ts_std,name='ts_std',arity=2)\n",
    "delay=make_function(function=_delay,name='delay',arity=2)\n",
    "delta=make_function(function=_delta,name='delta',arity=2)\n",
    "rank=make_function(function=_rank,name='rank',arity=1)\n",
    "sigmoid=make_function(function=_sigmoid,name='sigmoid',arity=1)\n",
    "correlation=make_function(function=_correlation,name='correlation',arity=3)\n",
    "covariance=make_function(function=_covariance,name='covariance',arity=3)\n",
    "scale=make_function(function=_scale,name='scale',arity=1)\n",
    "ts_rank=make_function(function=_ts_rank,name='ts_rank',arity=2)\n",
    "ts_sum=make_function(function=_ts_sum,name='ts_sum',arity=2)\n",
    "ts_product=make_function(function=_ts_product,name='ts_product',arity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e03be-88f0-46d7-ae73-a2eeafd3e76a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_function=[ts_max,ts_min,ts_mid,ts_mean,ts_std,delay,delta,rank,correlation,ts_rank]\n",
    "function_set=init_function+user_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf9b283-eda0-4aa8-a385-609fed2e8123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def rankIC_metric(y,y_pred,w=None):\n",
    "    \n",
    "    def cal_rankIC(df):\n",
    "        df.index=df.code\n",
    "        # 去极值\n",
    "        M=df.y_pred.mean()    #df.y_pred.median()\n",
    "        M1=df.y_pred.std()    #(df.y_pred-M).abs().median()\n",
    "        df.y_pred.loc[df.y_pred>M+3*M1]=M+3*M1    #5\n",
    "        df.y_pred.loc[df.y_pred<M-3*M1]=M-3*M1\n",
    "        # 行业市值中性化\n",
    "        day=df.date.iloc[0]\n",
    "        ind=inds[day].copy()\n",
    "        ind['mkv']=df.loc[ind.index,'mkv']\n",
    "        input_x=ind.dropna().astype(float)\n",
    "        input_y=df.loc[input_x.index,'y_pred']\n",
    "        y_true=df.loc[input_x.index,'y'].values\n",
    "        if len(input_x)==0:\n",
    "            return 0\n",
    "        else:\n",
    "            mod=sm.OLS(input_y,input_x)\n",
    "            res=mod.fit()\n",
    "            y_adj=res.resid\n",
    "            #标准化\n",
    "            y_adj=(y_adj-y_adj.mean())/y_adj.std()\n",
    "        \n",
    "            if len(np.unique(y_adj.values)) <=2:\n",
    "                return 0\n",
    "            else:\n",
    "                #return y_adj.corr(input_xy.mkt_delay,method='spearman')\n",
    "                return spearmanr(np.nan_to_num(y_adj.values),np.nan_to_num(y_true))[0]\n",
    "            \n",
    "    if len(np.unique(y_pred))<=2:\n",
    "        return 0\n",
    "    else:\n",
    "        try:\n",
    "            data=pd.DataFrame({'y_pred':y_pred,'y':y,'mkv':np.log(mkv_s),'code':test_code,'date':test_date})\n",
    "            res=data.groupby('date').apply(cal_rankIC)\n",
    "            return np.abs(np.nanmean(res))\n",
    "        except:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b690ee0-a5b8-4c3e-b8d2-925e90bb6b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rankIC=make_fitness(function=rankIC_metric,greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54acff7-bac8-4bb4-a3ed-e21edade2430",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gp=SymbolicTransformer(feature_names = fields,\n",
    "                            function_set = function_set, #所有算子\n",
    "                            generations = 3, #进化代数\n",
    "                            population_size = 100, #种群规模\n",
    "                            tournament_size = 10, #竞标赛规模\n",
    "                            p_crossover=0.4,\n",
    "                            p_subtree_mutation=0.05,\n",
    "                            p_hoist_mutation=0.01,\n",
    "                            p_point_mutation=0.03,\n",
    "                            p_point_replace=0.35,\n",
    "                            init_depth=(1,4),\n",
    "                            const_range = None,\n",
    "                            metric=rankIC,\n",
    "                            parsimony_coefficient = 'auto',\n",
    "                            low_memory=True,\n",
    "                            verbose=2,\n",
    "                            n_jobs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c8825-eb02-46ee-b6c9-a5dec07060e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gp.fit(np.nan_to_num(stock_test.loc[:,fields].values),np.nan_to_num(test_mkt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0b285-ce5d-4c52-b5a3-960fc1b353cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stock_all=pd.DataFrame({\n",
    "    # 'open':open_.loc[:,'20200101':'20210101'].values.reshape(-1),\n",
    "    #                      'close':close.loc[:,'20200101':'20210101'].values.reshape(-1),\n",
    "    #                      'high':high.loc[:,'20200101':'20210101'].values.reshape(-1),\n",
    "    #                      'low':low.loc[:,'20200101':'20210101'].values.reshape(-1),\n",
    "    #                      'vol':vol.loc[:,'20200101':'20210101'].values.reshape(-1),\n",
    "    #                      'amount':amount.loc[:,'20200101':'20210101'].values.reshape(-1),\n",
    "                'accelerated_turnover_rank_RC':pd.DataFrame(ff.read('accelerated_turnover_rank_RC').loc[ff.read('synergy').index,'20200101':'20240415'],index=open_.index).values.reshape(-1),\n",
    "                         'CSK_XYY_UP_DOWN_120D_RC':pd.DataFrame(ff.read('CSK_XYY_UP_DOWN_120D_RC').loc[ff.read('synergy').index,'20200101':'20240415'],index=open_.index).values.reshape(-1),\n",
    "                         'high_fre_vol_RC':pd.DataFrame(ff.read('high_fre_vol_RC').loc[ff.read('synergy').index,'20200101':'20240415'],index=open_.index).values.reshape(-1),\n",
    "                         'high_fre_diff_vol_RC':pd.DataFrame(ff.read('high_fre_diff_vol_RC').loc[ff.read('synergy').index,'20200101':'20240415'],index=open_.index).values.reshape(-1),\n",
    "                         'high_fre_absdiff_vol_RC':pd.DataFrame(ff.read('high_fre_absdiff_vol_RC').loc[ff.read('synergy').index,'20200101':'20240415'],index=open_.index).values.reshape(-1),\n",
    "                         'peak_count_vol_RC':pd.DataFrame(ff.read('peak_count_vol_RC').loc[ff.read('synergy').index,'20200101':'20240415'],index=open_.index).values.reshape(-1),\n",
    "                         'overnightsmart20_RC':pd.DataFrame(ff.read('overnightsmart20_RC').loc[ff.read('synergy').index,'20200101':'20240415'],index=open_.index).values.reshape(-1),\n",
    "                         'CTR_RC':pd.DataFrame(ff.read('CTR_RC').loc[ff.read('synergy').index,'20200101':'20240415'],index=open_.index).values.reshape(-1),\n",
    "                         'jumpCTR_RC':pd.DataFrame(ff.read('jumpCTR_RC').loc[ff.read('synergy').index,'20200101':'20240415'],index=open_.index).values.reshape(-1),\n",
    "                         'turnover_rate_proportion_l':pd.DataFrame(ff.read('turnover_rate_proportion_l').loc[ff.read('synergy').index,'20200101':'20240415'],index=open_.index).values.reshape(-1),\n",
    "                         'synergy':pd.DataFrame(ff.read('synergy').loc[ff.read('synergy').index,'20200101':'20240415'],index=open_.index).values.reshape(-1),\n",
    "                        })\n",
    "stock_all\n",
    "stock_code = list(np.repeat(list(ff.read('turnover_rate_proportion_l').index),len(ff.read('turnover_rate_proportion_l').loc[:,'20200101':'20240415'].columns)))\n",
    "date_code = list(np.tile(list(ff.read('turnover_rate_proportion_l').loc[:,'20200101':'20240415'].columns),len(list(ff.read('turnover_rate_proportion_l').index))))\n",
    "stock_all['code']= stock_code\n",
    "stock_all['date']=date_code\n",
    "stock_all['1'],stock_all['5'],stock_all['10'],stock_all['20'],stock_all['40'],stock_all['60']=1,5,10,20,40,60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456049a7-4a13-444f-9274-d0e7fbb67918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformed_factor = []\n",
    "for i, program in enumerate(test_gp._best_programs):\n",
    "    print(f'Program {i+1}: {program}')\n",
    "    transformed_X = program.execute(np.nan_to_num(stock_all.loc[:,fields].values))\n",
    "    transformed_factor_X = pd.DataFrame(transformed_X.reshape(ff.read('accelerated_turnover_rank_RC').shape[0],-1),index = ff.read('accelerated_turnover_rank_RC').index,columns = ff.read('accelerated_turnover_rank_RC').loc[:,'20200101':'20240415'].columns)\n",
    "    ff.run(-transformed_factor_X*ff.filter0.loc[:,'20200101':'20240415'], positions = 100, period = 1, fees = 0)\n",
    "    ff.run(transformed_factor_X*ff.filter0.loc[:,'20200101':'20240415'], positions = 100, period = 1, fees = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd15531-dccc-4a8f-898b-cde7ddde3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 截面分位数\n",
    "def _rank(data):\n",
    "    try:\n",
    "        data_df=pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        return np.nan_to_num((data_df.rank()/data_df.count()).values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "# 两组数据对应位置上的较大值\n",
    "def _max(data1,data2):  \n",
    "    try:\n",
    "        return np.maximum(data1,data2)\n",
    "    except:\n",
    "        return np.zeros(len(data1))\n",
    "\n",
    "# 两组数据对应位置上的较小值\n",
    "def _min(data1,data2):  \n",
    "    try:\n",
    "        return np.minimum(data1,data2)\n",
    "    except:\n",
    "        return np.zeros(len(data1))\n",
    "\n",
    "# 两组数据截面分位数之和\n",
    "def _rank_add(data1,data2):\n",
    "    try:\n",
    "        data1_df=pd.DataFrame(data1.reshape(*event.shape)).replace(0,np.nan)\n",
    "        data2_df=pd.DataFrame(data2.reshape(*event.shape)).replace(0,np.nan)\n",
    "        rank1 = data1_df.rank()/data1_df.count()\n",
    "        rank2 = data2_df.rank()/data2_df.count()\n",
    "        value = rank1+rank2\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data1))\n",
    "\n",
    "# 两组数据截面分位数之差\n",
    "def _rank_sub(data1,data2):\n",
    "    try:\n",
    "        data1_df=pd.DataFrame(data1.reshape(*event.shape)).replace(0,np.nan)\n",
    "        data2_df=pd.DataFrame(data2.reshape(*event.shape)).replace(0,np.nan)\n",
    "        rank1 = data1_df.rank()/data1_df.count()\n",
    "        rank2 = data2_df.rank()/data2_df.count()\n",
    "        value = rank1-rank2\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data1))\n",
    "\n",
    "# 两组数据截面分位数乘积\n",
    "def _rank_mul(data1,data2):\n",
    "    try:\n",
    "        data1_df=pd.DataFrame(data1.reshape(*event.shape)).replace(0,np.nan)\n",
    "        data2_df=pd.DataFrame(data2.reshape(*event.shape)).replace(0,np.nan)\n",
    "        rank1 = data1_df.rank()/data1_df.count()\n",
    "        rank2 = data2_df.rank()/data2_df.count()\n",
    "        value = rank1*rank2\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data1))\n",
    "\n",
    "# 两组数据截面分位数比值\n",
    "def _rank_div(data1,data2):\n",
    "    try:\n",
    "        data1_df=pd.DataFrame(data1.reshape(*event.shape)).replace(0,np.nan)\n",
    "        data2_df=pd.DataFrame(data2.reshape(*event.shape)).replace(0,np.nan)\n",
    "        rank1 = data1_df.rank()/data1_df.count()\n",
    "        rank2 = data2_df.rank()/data2_df.count()\n",
    "        value = rank1/rank2\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data1))\n",
    "\n",
    "# shift 1\n",
    "def _delay1(data):\n",
    "    try:\n",
    "        data_df=pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        return np.nan_to_num(data_df.shift(1,axis=1).values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "# shift 5\n",
    "def _delay5(data):\n",
    "    try:\n",
    "        data_df=pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        return np.nan_to_num(data_df.shift(5,axis=1).values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "# diff 1\n",
    "def _delta1(data):  \n",
    "    try:\n",
    "        data_df=pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        return np.nan_to_num(data_df.diff(1,axis=1).values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "# rolling 5天取std\n",
    "def _ts_std5(data):\n",
    "    try:\n",
    "        data_df=pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        value=data_df.rolling(5,min_periods=2,axis=1).std()\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "# rolling 10天取std\n",
    "def _ts_std10(data):\n",
    "    try:\n",
    "        data_df=pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        value=data_df.rolling(10,min_periods=5,axis=1).std()\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "# rolling 5天取最小值\n",
    "def _ts_min5(data):\n",
    "    try:\n",
    "        data_df=pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        value=data_df.rolling(5,min_periods=2,axis=1).min()\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "# rolling 10天取最小值\n",
    "def _ts_min10(data):\n",
    "    try:\n",
    "        data_df=pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        value=data_df.rolling(10,min_periods=5,axis=1).min()\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "# rolling 5天取最大值\n",
    "def _ts_max5(data):\n",
    "    try:\n",
    "        data_df=pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        value=data_df.rolling(5,min_periods=2,axis=1).max()\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "# rolling 10天取最大值\n",
    "def _ts_max10(data):\n",
    "    try:\n",
    "        data_df=pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        value=data_df.rolling(10,min_periods=5,axis=1).max()\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "# rolling 10天取最小值\n",
    "def _ts_cov10(data1, data2):\n",
    "    try:\n",
    "        data1_df=pd.DataFrame(data1.reshape(*event.shape)).replace(0,np.nan)\n",
    "        data2_df=pd.DataFrame(data2.reshape(*event.shape)).replace(0,np.nan)\n",
    "        value=data1_df.T.rolling(window=10, min_periods=5).cov(data2_df.T).T\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data1))\n",
    "\n",
    "# 时序协方差\n",
    "def _ts_cov5(data1, data2):\n",
    "    try:\n",
    "        data1_df=pd.DataFrame(data1.reshape(*event.shape)).replace(0,np.nan)\n",
    "        data2_df=pd.DataFrame(data2.reshape(*event.shape)).replace(0,np.nan)\n",
    "        value=data1_df.T.rolling(window=5, min_periods=2).cov(data2_df.T).T\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data1))\n",
    "\n",
    "def _ts_corr10(data1, data2):\n",
    "    try:\n",
    "        data1_df=pd.DataFrame(data1.reshape(*event.shape)).replace(0,np.nan)\n",
    "        data2_df=pd.DataFrame(data2.reshape(*event.shape)).replace(0,np.nan)\n",
    "        value=data1_df.T.rolling(window=10, min_periods=5).corr(data2_df.T).T\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data1))\n",
    "\n",
    "# 时序相关系数\n",
    "def _ts_corr5(data1, data2):\n",
    "    try:\n",
    "        data1_df=pd.DataFrame(data1.reshape(*event.shape)).replace(0,np.nan)\n",
    "        data2_df=pd.DataFrame(data2.reshape(*event.shape)).replace(0,np.nan)\n",
    "        value=data1_df.T.rolling(window=5, min_periods=2).corr(data2_df.T).T\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data1))\n",
    "\n",
    "# 时序 mean/std\n",
    "def _ts_ms10(data):\n",
    "    try:\n",
    "        data_df=pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        roll = data_df.rolling(window=10, min_periods=5,axis=1)\n",
    "        value = roll.mean() / roll.std()\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "    \n",
    "def _ts_ms5(data):\n",
    "    try:\n",
    "        data_df=pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        roll = data_df.rolling(window=5, min_periods=2,aixs=1)\n",
    "        value = roll.mean() / roll.std()\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "# 时序z分数\n",
    "def _ts_zscore10(data):\n",
    "    try:\n",
    "        data_df=pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        roll = data_df.rolling(window=10, min_periods=5,axis=1)\n",
    "        value = (data_df - roll.mean())/roll.std()\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "def _ts_zscore5(data):\n",
    "    try:\n",
    "        data_df=pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        roll = data_df.rolling(window=5, min_periods=2,axis=1)\n",
    "        value = (data_df - roll.mean())/roll.std()\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "# 时序pct_change\n",
    "def _ts_chg10(data):\n",
    "    try:\n",
    "        data_df = pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        value = data_df.pct_change(10, axis=1)\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "    \n",
    "def _ts_chg5(data):\n",
    "    try:\n",
    "        data_df = pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        value = data_df.pct_change(5, axis=1)\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "    \n",
    "def _ts_chg1(data):\n",
    "    try:\n",
    "        data_df = pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        value = data_df.pct_change(1, axis=1)\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "# 时序偏度\n",
    "def _ts_skew5(data):\n",
    "    try:\n",
    "        data_df = pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        value = data_df.rolling(5,min_periods=2,axis=1).skew()\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "    \n",
    "def _ts_skew10(data):\n",
    "    try:\n",
    "        data_df = pd.DataFrame(data.reshape(*event.shape)).replace(0,np.nan)\n",
    "        value = data_df.rolling(10,min_periods=5,axis=1).skew()\n",
    "        return np.nan_to_num(value.values.reshape(-1))\n",
    "    except:\n",
    "        return np.zeros(len(data))\n",
    "\n",
    "rank=make_function(function=_rank,name='rank',arity=1)\n",
    "max_=make_function(function=_max,name='max_',arity=2)\n",
    "min_=make_function(function=_min,name='min_',arity=2)\n",
    "rank_add=make_function(function=_rank_add,name='rank_add',arity=2)\n",
    "rank_sub=make_function(function=_rank_sub,name='rank_sub',arity=2)\n",
    "rank_mul=make_function(function=_rank_mul,name='rank_mul',arity=2)\n",
    "rank_div=make_function(function=_rank_div,name='rank_div',arity=2)\n",
    "delay1=make_function(function=_delay1,name='delay1',arity=1)\n",
    "delay5=make_function(function=_delay5,name='delay5',arity=1)\n",
    "delta1=make_function(function=_delta1,name='delta1',arity=1)\n",
    "ts_std5=make_function(function=_ts_std5,name='ts_std5',arity=1)\n",
    "ts_std10=make_function(function=_ts_std10,name='ts_std10',arity=1)\n",
    "ts_min5=make_function(function=_ts_min5,name='ts_min5',arity=1)\n",
    "ts_min10=make_function(function=_ts_min10,name='ts_min10',arity=1)\n",
    "ts_max5=make_function(function=_ts_max5,name='ts_max5',arity=1)\n",
    "ts_max10=make_function(function=_ts_max10,name='ts_max10',arity=1)\n",
    "ts_cov10=make_function(function=_ts_cov10,name='ts_cov10',arity=2)\n",
    "ts_cov5=make_function(function=_ts_cov5,name='ts_cov5',arity=2)\n",
    "ts_corr10=make_function(function=_ts_corr10,name='ts_corr10',arity=2)\n",
    "ts_corr5=make_function(function=_ts_corr5,name='ts_corr5',arity=2)\n",
    "ts_ms10=make_function(function=_ts_ms10,name='ts_ms10',arity=1)\n",
    "ts_ms5=make_function(function=_ts_ms5,name='ts_ms5',arity=1)\n",
    "ts_zscore10=make_function(function=_ts_zscore10,name='ts_zscore10',arity=1)\n",
    "ts_zscore5=make_function(function=_ts_zscore5,name='ts_zscore5',arity=1)\n",
    "ts_chg10=make_function(function=_ts_chg10,name='ts_chg10',arity=1)\n",
    "ts_chg5=make_function(function=_ts_chg5,name='ts_chg5',arity=1)\n",
    "ts_chg1=make_function(function=_ts_chg1,name='ts_chg1',arity=1)\n",
    "ts_skew10=make_function(function=_ts_skew10,name='ts_skew10',arity=1)\n",
    "ts_skew5=make_function(function=_ts_skew5,name='ts_skew5',arity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705fa996-0a73-48fd-9885-32b3a92fe877",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_set = ['add','sub','mul','div','sqrt','log','inv','abs','neg',rank,max_,min_,rank_add,rank_sub,rank_mul,rank_div,delay1,delay5,delta1,ts_std5,ts_std10,ts_min5,ts_min10,ts_max5,ts_max10,ts_cov10,ts_cov5,ts_corr10,ts_corr5,ts_ms10,ts_ms5,ts_zscore10,ts_zscore5,ts_chg10,ts_chg5,ts_chg1,ts_skew10,ts_skew5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a4421a-f3f0-451c-9344-72623da249c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gp=SymbolicTransformer(feature_names = fields,\n",
    "                            function_set = function_set, #所有算子\n",
    "                            generations = 3, #进化代数\n",
    "                            population_size = 100, #种群规模\n",
    "                            tournament_size = 10, #竞标赛规模\n",
    "                            p_crossover=0.4,\n",
    "                            p_subtree_mutation=0.05,\n",
    "                            p_hoist_mutation=0.01,\n",
    "                            p_point_mutation=0.03,\n",
    "                            p_point_replace=0.35,\n",
    "                            init_depth=(1,4),\n",
    "                            const_range = None,\n",
    "                            metric=rankIC,\n",
    "                            parsimony_coefficient = 'auto',\n",
    "                            low_memory=True,\n",
    "                            verbose=2,\n",
    "                            n_jobs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f011f-3991-4b9c-ab86-9e235130c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gp.fit(np.nan_to_num(stock_test.loc[:,fields].values),np.nan_to_num(test_mkt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c132456-3641-4232-896a-76c031e0524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_all=pd.DataFrame({\n",
    "    # 'open':open_.loc[:,'20200101':'20210101'].values.reshape(-1),\n",
    "    #                      'close':close.loc[:,'20200101':'20210101'].values.reshape(-1),\n",
    "    #                      'high':high.loc[:,'20200101':'20210101'].values.reshape(-1),\n",
    "    #                      'low':low.loc[:,'20200101':'20210101'].values.reshape(-1),\n",
    "    #                      'vol':vol.loc[:,'20200101':'20210101'].values.reshape(-1),\n",
    "    #                      'amount':amount.loc[:,'20200101':'20210101'].values.reshape(-1),\n",
    "                'accelerated_turnover_rank_RC':pd.DataFrame(ff.read('accelerated_turnover_rank_RC').loc[ff.read('synergy').index,'20200101':'20240101'],index=open_.index).values.reshape(-1),\n",
    "                         'CSK_XYY_UP_DOWN_120D_RC':pd.DataFrame(ff.read('CSK_XYY_UP_DOWN_120D_RC').loc[ff.read('synergy').index,'20200101':'20240101'],index=open_.index).values.reshape(-1),\n",
    "                         'high_fre_vol_RC':pd.DataFrame(ff.read('high_fre_vol_RC').loc[ff.read('synergy').index,'20200101':'20240101'],index=open_.index).values.reshape(-1),\n",
    "                         'high_fre_diff_vol_RC':pd.DataFrame(ff.read('high_fre_diff_vol_RC').loc[ff.read('synergy').index,'20200101':'20240101'],index=open_.index).values.reshape(-1),\n",
    "                         'high_fre_absdiff_vol_RC':pd.DataFrame(ff.read('high_fre_absdiff_vol_RC').loc[ff.read('synergy').index,'20200101':'20240101'],index=open_.index).values.reshape(-1),\n",
    "                         'peak_count_vol_RC':pd.DataFrame(ff.read('peak_count_vol_RC').loc[ff.read('synergy').index,'20200101':'20240101'],index=open_.index).values.reshape(-1),\n",
    "                         'overnightsmart20_RC':pd.DataFrame(ff.read('overnightsmart20_RC').loc[ff.read('synergy').index,'20200101':'20240101'],index=open_.index).values.reshape(-1),\n",
    "                         'CTR_RC':pd.DataFrame(ff.read('CTR_RC').loc[ff.read('synergy').index,'20200101':'20240101'],index=open_.index).values.reshape(-1),\n",
    "                         'jumpCTR_RC':pd.DataFrame(ff.read('jumpCTR_RC').loc[ff.read('synergy').index,'20200101':'20240101'],index=open_.index).values.reshape(-1),\n",
    "                         'turnover_rate_proportion_l':pd.DataFrame(ff.read('turnover_rate_proportion_l').loc[ff.read('synergy').index,'20200101':'20240101'],index=open_.index).values.reshape(-1),\n",
    "                         'synergy':pd.DataFrame(ff.read('synergy').loc[ff.read('synergy').index,'20200101':'20240101'],index=open_.index).values.reshape(-1),\n",
    "                        })\n",
    "stock_all\n",
    "stock_code = list(np.repeat(list(ff.read('turnover_rate_proportion_l').index),len(ff.read('turnover_rate_proportion_l').loc[:,'20200101':'20240101'].columns)))\n",
    "date_code = list(np.tile(list(ff.read('turnover_rate_proportion_l').loc[:,'20200101':'20240101'].columns),len(list(ff.read('turnover_rate_proportion_l').index))))\n",
    "stock_all['code']= stock_code\n",
    "stock_all['date']=date_code\n",
    "stock_all['1'],stock_all['5'],stock_all['10'],stock_all['20'],stock_all['40'],stock_all['60']=1,5,10,20,40,60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192915a0-0c4c-46a1-b5e3-32cf975c2646",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformed_factor = []\n",
    "for i, program in enumerate(test_gp._best_programs):\n",
    "    print(f'Program {i+1}: {program}')\n",
    "    transformed_X = program.execute(np.nan_to_num(stock_all.loc[:,fields].values))\n",
    "    transformed_factor_X = pd.DataFrame(transformed_X.reshape(ff.read('accelerated_turnover_rank_RC').shape[0],-1),index = ff.read('accelerated_turnover_rank_RC').index,columns = ff.read('accelerated_turnover_rank_RC').loc[:,'20200101':'20240101'].columns)\n",
    "    ff.run(-transformed_factor_X*ff.filter0.loc[:,'20200101':'20240101'], positions = 100, period = 1, fees = 0)\n",
    "    ff.run(transformed_factor_X*ff.filter0.loc[:,'20200101':'20240101'], positions = 100, period = 1, fees = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea668cb-fe84-4569-a743-f7f3e577f2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
